{"ast":null,"code":"'use strict';\n\nvar __extends = this && this.__extends || function () {\n  var extendStatics = function (d, b) {\n    extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p];\n    };\n    return extendStatics(d, b);\n  };\n  return function (d, b) {\n    if (typeof b !== \"function\" && b !== null) throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n    extendStatics(d, b);\n    function __() {\n      this.constructor = d;\n    }\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\nvar MediaTrack = require('./mediatrack');\nvar captureVideoFrames = require('./capturevideoframes');\nvar VideoProcessorEventObserver = require('./videoprocessoreventobserver');\nvar guessBrowser = require('../../webrtc/util').guessBrowser;\nvar DEFAULT_FRAME_RATE = require('../../util/constants').DEFAULT_FRAME_RATE;\n/**\n * A {@link VideoTrack} is a {@link Track} representing video.\n * @extends Track\n * @property {boolean} isStarted - Whether or not the {@link VideoTrack} has\n *   started; if the {@link VideoTrack} started, there is enough video data to\n *   begin playback\n * @property {boolean} isEnabled - Whether or not the {@link VideoTrack} is\n *   enabled; if the {@link VideoTrack} is not enabled, it is \"paused\"\n * @property {VideoTrack.Dimensions} dimensions - The {@link VideoTrack}'s\n *   {@link VideoTrack.Dimensions}\n * @property {Track.Kind} kind - \"video\"\n * @property {MediaStreamTrack} mediaStreamTrack - A video MediaStreamTrack\n * @property {?MediaStreamTrack} processedTrack - The source of processed video frames.\n * It is null if no VideoProcessor has been added.\n * @property {?VideoProcessor} processor - A {@link VideoProcessor} that is currently\n *   processing video frames. It is null if video frames are not being processed.\n * @emits VideoTrack#dimensionsChanged\n * @emits VideoTrack#disabled\n * @emits VideoTrack#enabled\n * @emits VideoTrack#started\n */\nvar VideoTrack = /** @class */function (_super) {\n  __extends(VideoTrack, _super);\n  /**\n   * Construct a {@link VideoTrack}.\n   * @param {MediaTrackTransceiver} mediaTrackTransceiver\n   * @param {{log: Log}} options\n   */\n  function VideoTrack(mediaTrackTransceiver, options) {\n    var _this = _super.call(this, mediaTrackTransceiver, options) || this;\n    Object.defineProperties(_this, {\n      _isCapturing: {\n        value: false,\n        writable: true\n      },\n      _inputFrame: {\n        value: null,\n        writable: true\n      },\n      _outputFrame: {\n        value: null,\n        writable: true\n      },\n      _processorEventObserver: {\n        value: null,\n        writable: true\n      },\n      _processorOptions: {\n        value: {},\n        writable: true\n      },\n      _stopCapture: {\n        value: function () {},\n        writable: true\n      },\n      _unmuteHandler: {\n        value: null,\n        writable: true\n      },\n      dimensions: {\n        enumerable: true,\n        value: {\n          width: null,\n          height: null\n        }\n      },\n      processor: {\n        enumerable: true,\n        value: null,\n        writable: true\n      }\n    });\n    _this._processorEventObserver = new (options.VideoProcessorEventObserver || VideoProcessorEventObserver)(_this._log);\n    return _this;\n  }\n  /**\n   * @private\n   */\n  VideoTrack.prototype._checkIfCanCaptureFrames = function (isPublishing) {\n    if (isPublishing === void 0) {\n      isPublishing = false;\n    }\n    var canCaptureFrames = true;\n    var message = '';\n    var _a = this.mediaStreamTrack,\n      enabled = _a.enabled,\n      readyState = _a.readyState;\n    if (!enabled) {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is disabled';\n    }\n    if (readyState === 'ended') {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is ended';\n    }\n    if (!this.processor) {\n      canCaptureFrames = false;\n      message = 'VideoProcessor not detected.';\n    }\n    if (!this._attachments.size && !isPublishing) {\n      canCaptureFrames = false;\n      message = 'VideoTrack is not publishing and there is no attached element.';\n    }\n    if (message) {\n      this._log.debug(message);\n    }\n    return {\n      canCaptureFrames: canCaptureFrames,\n      message: message\n    };\n  };\n  /**\n   * @private\n   */\n  VideoTrack.prototype._captureFrames = function () {\n    var _this = this;\n    if (this._isCapturing) {\n      this._log.debug('Ignoring captureFrames call. Capture is already in progress');\n      return;\n    }\n    if (!this._checkIfCanCaptureFrames().canCaptureFrames) {\n      this._isCapturing = false;\n      this._log.debug('Cannot capture frames. Ignoring captureFrames call.');\n      return;\n    }\n    this._isCapturing = true;\n    this._processorEventObserver.emit('start');\n    this._log.debug('Start capturing frames');\n    var inputFrameBufferType = this._processorOptions.inputFrameBufferType;\n    this._dummyEl.play().then(function () {\n      var process = function (videoFrame) {\n        var checkResult = _this._checkIfCanCaptureFrames();\n        if (!checkResult.canCaptureFrames) {\n          if (videoFrame) {\n            videoFrame.close();\n          }\n          _this._isCapturing = false;\n          _this._stopCapture();\n          _this._processorEventObserver.emit('stop', checkResult.message);\n          _this._log.debug('Cannot capture frames. Stopping capturing frames.');\n          return Promise.resolve();\n        }\n        var _a = _this.mediaStreamTrack.getSettings(),\n          _b = _a.width,\n          width = _b === void 0 ? 0 : _b,\n          _c = _a.height,\n          height = _c === void 0 ? 0 : _c;\n        // Setting the canvas' dimension triggers a redraw.\n        // Only set it if it has changed.\n        if (_this._outputFrame && _this._outputFrame.width !== width) {\n          _this._outputFrame.width = width;\n          _this._outputFrame.height = height;\n        }\n        if (_this._inputFrame) {\n          if (_this._inputFrame.width !== width) {\n            _this._inputFrame.width = width;\n            _this._inputFrame.height = height;\n          }\n          _this._inputFrame.getContext('2d').drawImage(_this._dummyEl, 0, 0, width, height);\n        }\n        var input = videoFrame || (['video', 'videoframe'].includes(inputFrameBufferType) ? _this._dummyEl : _this._inputFrame);\n        var result = null;\n        try {\n          result = _this.processor.processFrame(input, _this._outputFrame);\n        } catch (ex) {\n          _this._log.debug('Exception detected after calling processFrame.', ex);\n        }\n        return (result instanceof Promise ? result : Promise.resolve(result)).then(function () {\n          if (_this._outputFrame) {\n            if (typeof _this.processedTrack.requestFrame === 'function') {\n              _this.processedTrack.requestFrame();\n            }\n            _this._processorEventObserver.emit('stats');\n          }\n        });\n      };\n      _this._stopCapture = captureVideoFrames(_this._dummyEl, process, inputFrameBufferType);\n    }).catch(function (error) {\n      return _this._log.error('Video element cannot be played', {\n        error: error,\n        track: _this\n      });\n    });\n  };\n  /**\n   * @private\n   */\n  VideoTrack.prototype._initialize = function () {\n    var _this = this;\n    _super.prototype._initialize.call(this);\n    if (this._dummyEl) {\n      this._dummyEl.onloadedmetadata = function () {\n        if (dimensionsChanged(_this, _this._dummyEl)) {\n          _this.dimensions.width = _this._dummyEl.videoWidth;\n          _this.dimensions.height = _this._dummyEl.videoHeight;\n        }\n      };\n      this._dummyEl.onresize = function () {\n        if (dimensionsChanged(_this, _this._dummyEl)) {\n          _this.dimensions.width = _this._dummyEl.videoWidth;\n          _this.dimensions.height = _this._dummyEl.videoHeight;\n          if (_this.isStarted) {\n            _this._log.debug('Dimensions changed:', _this.dimensions);\n            _this.emit(VideoTrack.DIMENSIONS_CHANGED, _this);\n          }\n        }\n      };\n    }\n  };\n  /**\n   * @private\n   */\n  VideoTrack.prototype._restartProcessor = function () {\n    var processor = this.processor;\n    if (processor) {\n      var processorOptions = Object.assign({}, this._processorOptions);\n      this.removeProcessor(processor);\n      this.addProcessor(processor, processorOptions);\n    }\n  };\n  /**\n   * @private\n   */\n  VideoTrack.prototype._start = function (dummyEl) {\n    this.dimensions.width = dummyEl.videoWidth;\n    this.dimensions.height = dummyEl.videoHeight;\n    this._log.debug('Dimensions:', this.dimensions);\n    this.emit(VideoTrack.DIMENSIONS_CHANGED, this);\n    return _super.prototype._start.call(this, dummyEl);\n  };\n  /**\n   * Add a {@link VideoProcessor} to allow for custom processing of video frames belonging to a VideoTrack.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to use.\n   * @param {AddProcessorOptions} [options] - {@link AddProcessorOptions} to provide.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   videoTrack.addProcessor(new GrayScaleProcessor(100));\n   * });\n   */\n  VideoTrack.prototype.addProcessor = function (processor, options) {\n    var _this = this;\n    if (!processor || typeof processor.processFrame !== 'function') {\n      throw new Error('Received an invalid VideoProcessor from addProcessor.');\n    }\n    if (this.processor) {\n      throw new Error('A VideoProcessor has already been added.');\n    }\n    if (!this._dummyEl) {\n      throw new Error('VideoTrack has not been initialized.');\n    }\n    this._log.debug('Adding VideoProcessor to the VideoTrack', processor);\n    if (!this._unmuteHandler) {\n      this._unmuteHandler = function () {\n        _this._log.debug('mediaStreamTrack unmuted');\n        // NOTE(csantos): On certain scenarios where mediaStreamTrack is coming from muted to unmuted state,\n        // the processedTrack doesn't unmutes automatically although enabled is already set to true.\n        // This is a terminal state for the processedTrack and should be restarted. (VIDEO-4176)\n        if (_this.processedTrack.muted) {\n          _this._log.debug('mediaStreamTrack is unmuted but processedTrack is muted. Restarting processor.');\n          _this._restartProcessor();\n        }\n      };\n      if (this.mediaStreamTrack.addEventListener) {\n        this.mediaStreamTrack.addEventListener('unmute', this._unmuteHandler);\n      } else {\n        this.mediaStreamTrack.onunmute = this._unmuteHandler.bind(this);\n      }\n    }\n    this._processorOptions = options || {};\n    var _a = this._processorOptions,\n      inputFrameBufferType = _a.inputFrameBufferType,\n      outputFrameBufferContextType = _a.outputFrameBufferContextType;\n    if (typeof OffscreenCanvas === 'undefined' && inputFrameBufferType === 'offscreencanvas') {\n      throw new Error('OffscreenCanvas is not supported by this browser.');\n    }\n    if (inputFrameBufferType && inputFrameBufferType !== 'videoframe' && inputFrameBufferType !== 'video' && inputFrameBufferType !== 'canvas' && inputFrameBufferType !== 'offscreencanvas') {\n      throw new Error(\"Invalid inputFrameBufferType of \" + inputFrameBufferType);\n    }\n    if (!inputFrameBufferType) {\n      inputFrameBufferType = typeof OffscreenCanvas === 'undefined' ? 'canvas' : 'offscreencanvas';\n    }\n    var _b = this.mediaStreamTrack.getSettings(),\n      _c = _b.width,\n      width = _c === void 0 ? 0 : _c,\n      _d = _b.height,\n      height = _d === void 0 ? 0 : _d,\n      _e = _b.frameRate,\n      frameRate = _e === void 0 ? DEFAULT_FRAME_RATE : _e;\n    if (inputFrameBufferType === 'offscreencanvas') {\n      this._inputFrame = new OffscreenCanvas(width, height);\n    }\n    if (inputFrameBufferType === 'canvas') {\n      this._inputFrame = document.createElement('canvas');\n    }\n    if (this._inputFrame) {\n      this._inputFrame.width = width;\n      this._inputFrame.height = height;\n    }\n    this._outputFrame = document.createElement('canvas');\n    this._outputFrame.width = width;\n    this._outputFrame.height = height;\n    // NOTE(csantos): Initialize the rendering context for future renders. This also ensures\n    // that the correct type is used and on Firefox, it throws an exception if you try to capture\n    // frames prior calling getContext https://bugzilla.mozilla.org/show_bug.cgi?id=1572422\n    outputFrameBufferContextType = outputFrameBufferContextType || '2d';\n    var ctx = this._outputFrame.getContext(outputFrameBufferContextType);\n    if (!ctx) {\n      throw new Error(\"Cannot get outputFrameBufferContextType: \" + outputFrameBufferContextType + \".\");\n    }\n    // NOTE(csantos): Zero FPS means we can control when to render the next frame by calling requestFrame.\n    // Some browsers such as Firefox doesn't support requestFrame so we will use default, which is an undefined value.\n    // This means, the browser will use the highest FPS available.\n    var targetFps = typeof CanvasCaptureMediaStreamTrack !== 'undefined' && CanvasCaptureMediaStreamTrack.prototype &&\n    // eslint-disable-next-line\n    typeof CanvasCaptureMediaStreamTrack.prototype.requestFrame === 'function' ? 0 : undefined;\n    this.processedTrack = this._outputFrame.captureStream(targetFps).getTracks()[0];\n    this.processedTrack.enabled = this.mediaStreamTrack.enabled;\n    this.processor = processor;\n    this._processorEventObserver.emit('add', {\n      processor: processor,\n      captureHeight: height,\n      captureWidth: width,\n      inputFrameRate: frameRate,\n      isRemoteVideoTrack: this.toString().includes('RemoteVideoTrack'),\n      inputFrameBufferType: inputFrameBufferType,\n      outputFrameBufferContextType: outputFrameBufferContextType\n    });\n    this._updateElementsMediaStreamTrack();\n    this._captureFrames();\n    return this;\n  };\n  /**\n   * Create an HTMLVideoElement and attach the {@link VideoTrack} to it.\n   *\n   * The HTMLVideoElement's <code>srcObject</code> will be set to a new\n   * MediaStream containing the {@link VideoTrack}'s MediaStreamTrack.\n   *\n   * @returns {HTMLVideoElement} videoElement\n   * @example\n   * const Video = require('twilio-video');\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const videoElement = videoTrack.attach();\n   *   document.body.appendChild(videoElement);\n   * });\n  */ /**\n     * Attach the {@link VideoTrack} to an existing HTMLMediaElement. The\n     * HTMLMediaElement could be an HTMLAudioElement or an HTMLVideoElement.\n     *\n     * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n     * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n     * MediaStreamTrack; otherwise, it adds the {@link MediaTrack}'s\n     * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n     * MediaStreamTracks of the same kind on the MediaStream, this method removes\n     * them.\n     *\n     * @param {HTMLMediaElement} mediaElement - The HTMLMediaElement to attach to\n     * @returns {HTMLMediaElement} mediaElement\n     * @example\n     * const Video = require('twilio-video');\n     *\n     * const videoElement = document.createElement('video');\n     * document.body.appendChild(videoElement);\n     *\n     * Video.createLocalVideoTrack().then(function(videoTrack) {\n     *   videoTrack.attach(videoElement);\n     * });\n     */ /**\n        * Attach the {@link VideoTrack} to an HTMLMediaElement selected by\n        * <code>document.querySelector</code>. The HTMLMediaElement could be an\n        * HTMLAudioElement or an HTMLVideoElement.\n        *\n        * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n        * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n        * MediaStreamTrack; otherwise, it adds the {@link VideoTrack}'s\n        * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n        * MediaStreamTracks of the same kind on the MediaStream, this method removes\n        * them.\n        *\n        * @param {string} selector - A query selector for the HTMLMediaElement to\n        *   attach to\n        * @returns {HTMLMediaElement} mediaElement\n        * @example\n        * const Video = require('twilio-video');\n        *\n        * const videoElement = document.createElement('video');\n        * videoElement.id = 'my-video-element';\n        * document.body.appendChild(videoElement);\n        *\n        * Video.createLocalVideoTrack().then(function(track) {\n        *   track.attach('#my-video-element');\n        * });\n        */\n  VideoTrack.prototype.attach = function () {\n    var result = _super.prototype.attach.apply(this, arguments);\n    if (this.processor) {\n      this._captureFrames();\n    }\n    return result;\n  };\n  /**\n   * Detach the {@link VideoTrack} from all previously attached HTMLMediaElements.\n   * @returns {Array<HTMLMediaElement>} mediaElements\n   * @example\n   * const mediaElements = videoTrack.detach();\n   * mediaElements.forEach(mediaElement => mediaElement.remove());\n  */ /**\n     * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement.\n     * @param {HTMLMediaElement} mediaElement - One of the HTMLMediaElements to\n     *   which the {@link VideoTrack} is attached\n     * @returns {HTMLMediaElement} mediaElement\n     * @example\n     * const videoElement = document.getElementById('my-video-element');\n     * videoTrack.detach(videoElement).remove();\n     */ /**\n        * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement\n        *   specified by <code>document.querySelector</code>.\n        * @param {string} selector - The query selector of HTMLMediaElement to which\n        *    the {@link VideoTrack} is attached\n        * @returns {HTMLMediaElement} mediaElement\n        * @example\n        * videoTrack.detach('#my-video-element').remove();\n        */\n  VideoTrack.prototype.detach = function () {\n    return _super.prototype.detach.apply(this, arguments);\n  };\n  /**\n   * Remove the previously added {@link VideoProcessor} using `addProcessor` API.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to remove.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const grayScaleProcessor = new GrayScaleProcessor(100);\n   *   videoTrack.addProcessor(grayScaleProcessor);\n   *   document.getElementById('remove-button').onclick = () => videoTrack.removeProcessor(grayScaleProcessor);\n   * });\n   */\n  VideoTrack.prototype.removeProcessor = function (processor) {\n    if (!processor) {\n      throw new Error('Received an invalid VideoProcessor from removeProcessor.');\n    }\n    if (!this.processor) {\n      throw new Error('No existing VideoProcessor detected.');\n    }\n    if (processor !== this.processor) {\n      throw new Error('The provided VideoProcessor is different than the existing one.');\n    }\n    this._processorEventObserver.emit('remove');\n    this._log.debug('Removing VideoProcessor from the VideoTrack', processor);\n    this._stopCapture();\n    this._stopCapture = function () {};\n    this.mediaStreamTrack.removeEventListener('unmute', this._unmuteHandler);\n    this._processorOptions = {};\n    this._unmuteHandler = null;\n    this._isCapturing = false;\n    this.processor = null;\n    this.processedTrack = null;\n    this._inputFrame = null;\n    this._outputFrame = null;\n    this._updateElementsMediaStreamTrack();\n    return this;\n  };\n  return VideoTrack;\n}(MediaTrack);\nVideoTrack.DIMENSIONS_CHANGED = 'dimensionsChanged';\nfunction dimensionsChanged(track, elem) {\n  return track.dimensions.width !== elem.videoWidth || track.dimensions.height !== elem.videoHeight;\n}\n/**\n * A {@link VideoTrack}'s width and height.\n * @typedef {object} VideoTrack.Dimensions\n * @property {?number} width - The {@link VideoTrack}'s width or null if the\n *   {@link VideoTrack} has not yet started\n * @property {?number} height - The {@link VideoTrack}'s height or null if the\n *   {@link VideoTrack} has not yet started\n */\n/**\n * A {@link VideoProcessor}, when added via {@link VideoTrack#addProcessor},\n * is used to process incoming video frames before\n * sending to the encoder or renderer.\n * @typedef {object} VideoProcessor\n * @property {function} processFrame - A callback to receive input and output frame buffers for processing.\n * The input frame buffer contains the original video frame which can be used for additional processing\n * such as applying filters to it. The output frame buffer is used to receive the processed video frame\n * before sending to the encoder or renderer.\n *\n * Any exception raised (either synchronously or asynchronously) in `processFrame` will result in the frame being dropped.\n * This callback has the following signature:<br/><br/>\n * <code>processFrame(</code><br/>\n * &nbsp;&nbsp;<code>inputFrameBuffer: OffscreenCanvas | HTMLCanvasElement | HTMLVideoElement | VideoFrame,</code><br/>\n * &nbsp;&nbsp;<code>outputFrameBuffer: HTMLCanvasElement</code><br/>\n * <code>): Promise&lt;void&gt; | void;</code>\n *\n * @example\n * class GrayScaleProcessor {\n *   constructor(percentage) {\n *     this.percentage = percentage;\n *   }\n *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n *     const context = outputFrameBuffer.getContext('2d');\n *     context.filter = `grayscale(${this.percentage}%)`;\n *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n *   }\n * }\n */\n/**\n * Possible options to provide to {@link LocalVideoTrack#addProcessor} and {@link RemoteVideoTrack#addProcessor}.\n * @typedef {object} AddProcessorOptions\n * @property {string} [inputFrameBufferType=\"offscreencanvas\"] - This option allows you to specify what kind of input you want to receive in your\n * Video Processor. The default is `offscreencanvas` and will fallback to a regular `canvas` if the browser does not support it.\n * Possible values include the following.\n * <br/>\n * <br/>\n * `videoframe` - Your Video Processor will receive a [VideoFrame](https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame).\n * On browsers that do not support `VideoFrame`, it will receive an [HTMLVideoElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement) instead.\n * <br/>\n * <br/>\n * `offscreencanvas` - Your Video Processor will receive an [OffscreenCanvas](https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas)\n * which is good for canvas-related processing that can be rendered off screen.\n * <br/>\n * <br/>\n * `canvas` - Your Video Processor will receive an [HTMLCanvasElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement).\n * This is recommended on browsers that doesn't support `OffscreenCanvas`, or if you need to render the frame on the screen.\n * <br/>\n * <br/>\n * `video` - Your Video Processor will receive an [HTMLVideoElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement).\n * Use this option if you are processing the frame using WebGL or if you only need to [draw](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage)\n * the frame directly to your output canvas.\n * @property {string} [outputFrameBufferContextType=\"2d\"] - The SDK needs the [context type](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext)\n * that your Video Processor uses in order to properly generate the processed track. For example, if your Video Processor uses WebGL2 (`canvas.getContext('webgl2')`),\n * you should set `outputFrameBufferContextType` to `webgl2`. If you're using Canvas 2D processing (`canvas.getContext('2d')`),\n * you should set `outputFrameBufferContextType` to `2d`. If the output frame is an [ImageBitmap](https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap),\n * you should set `outputFrameBufferContextType` to `bitmaprenderer`.\n */\n/**\n * The {@link VideoTrack}'s dimensions changed.\n * @param {VideoTrack} track - The {@link VideoTrack} whose dimensions changed\n * @event VideoTrack#dimensionsChanged\n */\n/**\n * The {@link VideoTrack} was disabled, i.e. \"paused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was disabled\n * @event VideoTrack#disabled\n */\n/**\n * The {@link VideoTrack} was enabled, i.e. \"unpaused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was enabled\n * @event VideoTrack#enabled\n */\n/**\n * The {@link VideoTrack} started. This means there is enough video data to\n * begin playback.\n * @param {VideoTrack} track - The {@link VideoTrack} that started\n * @event VideoTrack#started\n */\nmodule.exports = VideoTrack;","map":{"version":3,"names":["MediaTrack","require","captureVideoFrames","VideoProcessorEventObserver","guessBrowser","DEFAULT_FRAME_RATE","VideoTrack","_super","__extends","mediaTrackTransceiver","options","_this","call","Object","defineProperties","_isCapturing","value","writable","_inputFrame","_outputFrame","_processorEventObserver","_processorOptions","_stopCapture","_unmuteHandler","dimensions","enumerable","width","height","processor","_log","prototype","_checkIfCanCaptureFrames","isPublishing","canCaptureFrames","message","_a","mediaStreamTrack","enabled","readyState","_attachments","size","debug","_captureFrames","emit","inputFrameBufferType","_dummyEl","play","then","process","videoFrame","checkResult","close","Promise","resolve","getSettings","_b","_c","getContext","drawImage","input","includes","result","processFrame","ex","processedTrack","requestFrame","catch","error","track","_initialize","onloadedmetadata","dimensionsChanged","videoWidth","videoHeight","onresize","isStarted","DIMENSIONS_CHANGED","_restartProcessor","processorOptions","assign","removeProcessor","addProcessor","_start","dummyEl","Error","muted","addEventListener","onunmute","bind","outputFrameBufferContextType","OffscreenCanvas","_d","_e","frameRate","document","createElement","ctx","targetFps","CanvasCaptureMediaStreamTrack","undefined","captureStream","getTracks","captureHeight","captureWidth","inputFrameRate","isRemoteVideoTrack","toString","_updateElementsMediaStreamTrack","attach","apply","arguments","detach","removeEventListener","elem","module","exports"],"sources":["C:\\Users\\gamin\\OneDrive\\Desktop\\Project\\Whiteboard\\live-whiteboard-app\\whiteboard-frontend\\node_modules\\twilio-video\\lib\\media\\track\\videotrack.js"],"sourcesContent":["'use strict';\n\nconst MediaTrack = require('./mediatrack');\nconst captureVideoFrames = require('./capturevideoframes');\nconst VideoProcessorEventObserver = require('./videoprocessoreventobserver');\nconst { guessBrowser } = require('../../webrtc/util');\nconst { DEFAULT_FRAME_RATE } = require('../../util/constants');\n\n/**\n * A {@link VideoTrack} is a {@link Track} representing video.\n * @extends Track\n * @property {boolean} isStarted - Whether or not the {@link VideoTrack} has\n *   started; if the {@link VideoTrack} started, there is enough video data to\n *   begin playback\n * @property {boolean} isEnabled - Whether or not the {@link VideoTrack} is\n *   enabled; if the {@link VideoTrack} is not enabled, it is \"paused\"\n * @property {VideoTrack.Dimensions} dimensions - The {@link VideoTrack}'s\n *   {@link VideoTrack.Dimensions}\n * @property {Track.Kind} kind - \"video\"\n * @property {MediaStreamTrack} mediaStreamTrack - A video MediaStreamTrack\n * @property {?MediaStreamTrack} processedTrack - The source of processed video frames.\n * It is null if no VideoProcessor has been added.\n * @property {?VideoProcessor} processor - A {@link VideoProcessor} that is currently\n *   processing video frames. It is null if video frames are not being processed.\n * @emits VideoTrack#dimensionsChanged\n * @emits VideoTrack#disabled\n * @emits VideoTrack#enabled\n * @emits VideoTrack#started\n */\nclass VideoTrack extends MediaTrack {\n  /**\n   * Construct a {@link VideoTrack}.\n   * @param {MediaTrackTransceiver} mediaTrackTransceiver\n   * @param {{log: Log}} options\n   */\n  constructor(mediaTrackTransceiver, options) {\n    super(mediaTrackTransceiver, options);\n    Object.defineProperties(this, {\n      _isCapturing: {\n        value: false,\n        writable: true\n      },\n      _inputFrame: {\n        value: null,\n        writable: true\n      },\n      _outputFrame: {\n        value: null,\n        writable: true\n      },\n      _processorEventObserver: {\n        value: null,\n        writable: true,\n      },\n      _processorOptions: {\n        value: {},\n        writable: true,\n      },\n      _stopCapture: {\n        value: () => {},\n        writable: true\n      },\n      _unmuteHandler: {\n        value: null,\n        writable: true\n      },\n      dimensions: {\n        enumerable: true,\n        value: {\n          width: null,\n          height: null\n        }\n      },\n      processor: {\n        enumerable: true,\n        value: null,\n        writable: true\n      }\n    });\n\n    this._processorEventObserver = new (options.VideoProcessorEventObserver || VideoProcessorEventObserver)(this._log);\n\n    return this;\n  }\n\n  /**\n   * @private\n   */\n  _checkIfCanCaptureFrames(isPublishing = false) {\n    let canCaptureFrames = true;\n    let message = '';\n    const { enabled, readyState } = this.mediaStreamTrack;\n\n    if (!enabled) {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is disabled';\n    }\n    if (readyState === 'ended') {\n      canCaptureFrames = false;\n      message = 'MediaStreamTrack is ended';\n    }\n    if (!this.processor) {\n      canCaptureFrames = false;\n      message = 'VideoProcessor not detected.';\n    }\n    if (!this._attachments.size && !isPublishing) {\n      canCaptureFrames = false;\n      message = 'VideoTrack is not publishing and there is no attached element.';\n    }\n\n    if (message) {\n      this._log.debug(message);\n    }\n    return { canCaptureFrames, message };\n  }\n\n  /**\n   * @private\n   */\n  _captureFrames() {\n    if (this._isCapturing) {\n      this._log.debug('Ignoring captureFrames call. Capture is already in progress');\n      return;\n    }\n    if (!this._checkIfCanCaptureFrames().canCaptureFrames) {\n      this._isCapturing = false;\n      this._log.debug('Cannot capture frames. Ignoring captureFrames call.');\n      return;\n    }\n    this._isCapturing = true;\n    this._processorEventObserver.emit('start');\n    this._log.debug('Start capturing frames');\n\n    const { inputFrameBufferType } = this._processorOptions;\n\n    this._dummyEl.play().then(() => {\n      const process = videoFrame => {\n        const checkResult = this._checkIfCanCaptureFrames();\n        if (!checkResult.canCaptureFrames) {\n          if (videoFrame) {\n            videoFrame.close();\n          }\n          this._isCapturing = false;\n          this._stopCapture();\n          this._processorEventObserver.emit('stop', checkResult.message);\n          this._log.debug('Cannot capture frames. Stopping capturing frames.');\n          return Promise.resolve();\n        }\n        const { width = 0, height = 0 } = this.mediaStreamTrack.getSettings();\n        // Setting the canvas' dimension triggers a redraw.\n        // Only set it if it has changed.\n        if (this._outputFrame && this._outputFrame.width !== width) {\n          this._outputFrame.width = width;\n          this._outputFrame.height = height;\n        }\n        if (this._inputFrame) {\n          if (this._inputFrame.width !== width) {\n            this._inputFrame.width = width;\n            this._inputFrame.height = height;\n          }\n          this._inputFrame.getContext('2d').drawImage(\n            this._dummyEl,\n            0,\n            0,\n            width,\n            height\n          );\n        }\n        const input = videoFrame || (\n          ['video', 'videoframe'].includes(inputFrameBufferType)\n            ? this._dummyEl\n            : this._inputFrame\n        );\n        let result = null;\n\n        try {\n          result = this.processor.processFrame(input, this._outputFrame);\n        } catch (ex) {\n          this._log.debug('Exception detected after calling processFrame.', ex);\n        }\n        return ((result instanceof Promise) ? result : Promise.resolve(result))\n          .then(() => {\n            if (this._outputFrame) {\n              if (typeof this.processedTrack.requestFrame === 'function') {\n                this.processedTrack.requestFrame();\n              }\n              this._processorEventObserver.emit('stats');\n            }\n          });\n      };\n      this._stopCapture = captureVideoFrames(\n        this._dummyEl,\n        process,\n        inputFrameBufferType\n      );\n    }).catch(error => this._log.error(\n      'Video element cannot be played',\n      { error, track: this }\n    ));\n  }\n\n  /**\n   * @private\n   */\n  _initialize() {\n    super._initialize();\n    if (this._dummyEl) {\n      this._dummyEl.onloadedmetadata = () => {\n        if (dimensionsChanged(this, this._dummyEl)) {\n          this.dimensions.width = this._dummyEl.videoWidth;\n          this.dimensions.height = this._dummyEl.videoHeight;\n        }\n      };\n      this._dummyEl.onresize = () => {\n        if (dimensionsChanged(this, this._dummyEl)) {\n          this.dimensions.width = this._dummyEl.videoWidth;\n          this.dimensions.height = this._dummyEl.videoHeight;\n          if (this.isStarted) {\n            this._log.debug('Dimensions changed:', this.dimensions);\n            this.emit(VideoTrack.DIMENSIONS_CHANGED, this);\n          }\n        }\n      };\n    }\n  }\n\n  /**\n   * @private\n   */\n  _restartProcessor() {\n    const processor = this.processor;\n    if (processor) {\n      const processorOptions = Object.assign({}, this._processorOptions);\n      this.removeProcessor(processor);\n      this.addProcessor(processor, processorOptions);\n    }\n  }\n\n  /**\n   * @private\n   */\n  _start(dummyEl) {\n    this.dimensions.width = dummyEl.videoWidth;\n    this.dimensions.height = dummyEl.videoHeight;\n\n    this._log.debug('Dimensions:', this.dimensions);\n    this.emit(VideoTrack.DIMENSIONS_CHANGED, this);\n    return super._start.call(this, dummyEl);\n  }\n\n  /**\n   * Add a {@link VideoProcessor} to allow for custom processing of video frames belonging to a VideoTrack.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to use.\n   * @param {AddProcessorOptions} [options] - {@link AddProcessorOptions} to provide.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   videoTrack.addProcessor(new GrayScaleProcessor(100));\n   * });\n   */\n  addProcessor(processor, options) {\n    if (!processor || typeof processor.processFrame !== 'function') {\n      throw new Error('Received an invalid VideoProcessor from addProcessor.');\n    }\n    if (this.processor) {\n      throw new Error('A VideoProcessor has already been added.');\n    }\n    if (!this._dummyEl) {\n      throw new Error('VideoTrack has not been initialized.');\n    }\n\n    this._log.debug('Adding VideoProcessor to the VideoTrack', processor);\n\n    if (!this._unmuteHandler) {\n      this._unmuteHandler = () => {\n        this._log.debug('mediaStreamTrack unmuted');\n        // NOTE(csantos): On certain scenarios where mediaStreamTrack is coming from muted to unmuted state,\n        // the processedTrack doesn't unmutes automatically although enabled is already set to true.\n        // This is a terminal state for the processedTrack and should be restarted. (VIDEO-4176)\n        if (this.processedTrack.muted) {\n          this._log.debug('mediaStreamTrack is unmuted but processedTrack is muted. Restarting processor.');\n          this._restartProcessor();\n        }\n      };\n      if (this.mediaStreamTrack.addEventListener) {\n        this.mediaStreamTrack.addEventListener('unmute', this._unmuteHandler);\n      } else {\n        this.mediaStreamTrack.onunmute = this._unmuteHandler.bind(this);\n      }\n    }\n\n    this._processorOptions = options || {};\n    let { inputFrameBufferType, outputFrameBufferContextType } = this._processorOptions;\n    if (typeof OffscreenCanvas === 'undefined' && inputFrameBufferType === 'offscreencanvas') {\n      throw new Error('OffscreenCanvas is not supported by this browser.');\n    }\n    if (inputFrameBufferType\n      && inputFrameBufferType !== 'videoframe'\n      && inputFrameBufferType !== 'video'\n      && inputFrameBufferType !== 'canvas'\n      && inputFrameBufferType !== 'offscreencanvas') {\n      throw new Error(`Invalid inputFrameBufferType of ${inputFrameBufferType}`);\n    }\n    if (!inputFrameBufferType) {\n      inputFrameBufferType = typeof OffscreenCanvas === 'undefined' ? 'canvas' : 'offscreencanvas';\n    }\n\n    const { width = 0, height = 0, frameRate = DEFAULT_FRAME_RATE } = this.mediaStreamTrack.getSettings();\n    if (inputFrameBufferType === 'offscreencanvas') {\n      this._inputFrame = new OffscreenCanvas(width, height);\n    }\n    if (inputFrameBufferType === 'canvas') {\n      this._inputFrame = document.createElement('canvas');\n    }\n    if (this._inputFrame) {\n      this._inputFrame.width = width;\n      this._inputFrame.height = height;\n    }\n\n    this._outputFrame = document.createElement('canvas');\n    this._outputFrame.width = width;\n    this._outputFrame.height = height;\n\n    // NOTE(csantos): Initialize the rendering context for future renders. This also ensures\n    // that the correct type is used and on Firefox, it throws an exception if you try to capture\n    // frames prior calling getContext https://bugzilla.mozilla.org/show_bug.cgi?id=1572422\n    outputFrameBufferContextType = outputFrameBufferContextType || '2d';\n\n    const ctx = this._outputFrame.getContext(outputFrameBufferContextType);\n    if (!ctx) {\n      throw new Error(`Cannot get outputFrameBufferContextType: ${outputFrameBufferContextType}.`);\n    }\n\n    // NOTE(csantos): Zero FPS means we can control when to render the next frame by calling requestFrame.\n    // Some browsers such as Firefox doesn't support requestFrame so we will use default, which is an undefined value.\n    // This means, the browser will use the highest FPS available.\n    const targetFps = typeof CanvasCaptureMediaStreamTrack !== 'undefined' && CanvasCaptureMediaStreamTrack.prototype &&\n      // eslint-disable-next-line\n      typeof CanvasCaptureMediaStreamTrack.prototype.requestFrame === 'function' ? 0 : undefined;\n\n    this.processedTrack = this._outputFrame.captureStream(targetFps).getTracks()[0];\n    this.processedTrack.enabled = this.mediaStreamTrack.enabled;\n    this.processor = processor;\n\n    this._processorEventObserver.emit('add', {\n      processor,\n      captureHeight: height,\n      captureWidth: width,\n      inputFrameRate: frameRate,\n      isRemoteVideoTrack: this.toString().includes('RemoteVideoTrack'),\n      inputFrameBufferType,\n      outputFrameBufferContextType\n    });\n    this._updateElementsMediaStreamTrack();\n    this._captureFrames();\n    return this;\n  }\n\n  /**\n   * Create an HTMLVideoElement and attach the {@link VideoTrack} to it.\n   *\n   * The HTMLVideoElement's <code>srcObject</code> will be set to a new\n   * MediaStream containing the {@link VideoTrack}'s MediaStreamTrack.\n   *\n   * @returns {HTMLVideoElement} videoElement\n   * @example\n   * const Video = require('twilio-video');\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const videoElement = videoTrack.attach();\n   *   document.body.appendChild(videoElement);\n   * });\n  *//**\n   * Attach the {@link VideoTrack} to an existing HTMLMediaElement. The\n   * HTMLMediaElement could be an HTMLAudioElement or an HTMLVideoElement.\n   *\n   * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n   * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n   * MediaStreamTrack; otherwise, it adds the {@link MediaTrack}'s\n   * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n   * MediaStreamTracks of the same kind on the MediaStream, this method removes\n   * them.\n   *\n   * @param {HTMLMediaElement} mediaElement - The HTMLMediaElement to attach to\n   * @returns {HTMLMediaElement} mediaElement\n   * @example\n   * const Video = require('twilio-video');\n   *\n   * const videoElement = document.createElement('video');\n   * document.body.appendChild(videoElement);\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   videoTrack.attach(videoElement);\n   * });\n  *//**\n   * Attach the {@link VideoTrack} to an HTMLMediaElement selected by\n   * <code>document.querySelector</code>. The HTMLMediaElement could be an\n   * HTMLAudioElement or an HTMLVideoElement.\n   *\n   * If the HTMLMediaElement's <code>srcObject</code> is not set to a MediaStream,\n   * this method sets it to a new MediaStream containing the {@link VideoTrack}'s\n   * MediaStreamTrack; otherwise, it adds the {@link VideoTrack}'s\n   * MediaStreamTrack to the existing MediaStream. Finally, if there are any other\n   * MediaStreamTracks of the same kind on the MediaStream, this method removes\n   * them.\n   *\n   * @param {string} selector - A query selector for the HTMLMediaElement to\n   *   attach to\n   * @returns {HTMLMediaElement} mediaElement\n   * @example\n   * const Video = require('twilio-video');\n   *\n   * const videoElement = document.createElement('video');\n   * videoElement.id = 'my-video-element';\n   * document.body.appendChild(videoElement);\n   *\n   * Video.createLocalVideoTrack().then(function(track) {\n   *   track.attach('#my-video-element');\n   * });\n   */\n  attach() {\n    const result = super.attach.apply(this, arguments);\n    if (this.processor) {\n      this._captureFrames();\n    }\n    return result;\n  }\n\n  /**\n   * Detach the {@link VideoTrack} from all previously attached HTMLMediaElements.\n   * @returns {Array<HTMLMediaElement>} mediaElements\n   * @example\n   * const mediaElements = videoTrack.detach();\n   * mediaElements.forEach(mediaElement => mediaElement.remove());\n  *//**\n   * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement.\n   * @param {HTMLMediaElement} mediaElement - One of the HTMLMediaElements to\n   *   which the {@link VideoTrack} is attached\n   * @returns {HTMLMediaElement} mediaElement\n   * @example\n   * const videoElement = document.getElementById('my-video-element');\n   * videoTrack.detach(videoElement).remove();\n  *//**\n   * Detach the {@link VideoTrack} from a previously attached HTMLMediaElement\n   *   specified by <code>document.querySelector</code>.\n   * @param {string} selector - The query selector of HTMLMediaElement to which\n   *    the {@link VideoTrack} is attached\n   * @returns {HTMLMediaElement} mediaElement\n   * @example\n   * videoTrack.detach('#my-video-element').remove();\n   */\n  detach() {\n    return super.detach.apply(this, arguments);\n  }\n\n  /**\n   * Remove the previously added {@link VideoProcessor} using `addProcessor` API.\n   * @param {VideoProcessor} processor - The {@link VideoProcessor} to remove.\n   * @returns {this}\n   * @example\n   * class GrayScaleProcessor {\n   *   constructor(percentage) {\n   *     this.percentage = percentage;\n   *   }\n   *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n   *     const context = outputFrameBuffer.getContext('2d');\n   *     context.filter = `grayscale(${this.percentage}%)`;\n   *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n   *   }\n   * }\n   *\n   * Video.createLocalVideoTrack().then(function(videoTrack) {\n   *   const grayScaleProcessor = new GrayScaleProcessor(100);\n   *   videoTrack.addProcessor(grayScaleProcessor);\n   *   document.getElementById('remove-button').onclick = () => videoTrack.removeProcessor(grayScaleProcessor);\n   * });\n   */\n  removeProcessor(processor) {\n    if (!processor) {\n      throw new Error('Received an invalid VideoProcessor from removeProcessor.');\n    }\n    if (!this.processor) {\n      throw new Error('No existing VideoProcessor detected.');\n    }\n    if (processor !== this.processor) {\n      throw new Error('The provided VideoProcessor is different than the existing one.');\n    }\n\n    this._processorEventObserver.emit('remove');\n    this._log.debug('Removing VideoProcessor from the VideoTrack', processor);\n    this._stopCapture();\n    this._stopCapture = () => {};\n    this.mediaStreamTrack.removeEventListener('unmute', this._unmuteHandler);\n    this._processorOptions = {};\n    this._unmuteHandler = null;\n    this._isCapturing = false;\n\n    this.processor = null;\n    this.processedTrack = null;\n    this._inputFrame = null;\n    this._outputFrame = null;\n\n    this._updateElementsMediaStreamTrack();\n    return this;\n  }\n}\n\nVideoTrack.DIMENSIONS_CHANGED = 'dimensionsChanged';\n\nfunction dimensionsChanged(track, elem) {\n  return track.dimensions.width !== elem.videoWidth\n    || track.dimensions.height !== elem.videoHeight;\n}\n\n/**\n * A {@link VideoTrack}'s width and height.\n * @typedef {object} VideoTrack.Dimensions\n * @property {?number} width - The {@link VideoTrack}'s width or null if the\n *   {@link VideoTrack} has not yet started\n * @property {?number} height - The {@link VideoTrack}'s height or null if the\n *   {@link VideoTrack} has not yet started\n */\n\n/**\n * A {@link VideoProcessor}, when added via {@link VideoTrack#addProcessor},\n * is used to process incoming video frames before\n * sending to the encoder or renderer.\n * @typedef {object} VideoProcessor\n * @property {function} processFrame - A callback to receive input and output frame buffers for processing.\n * The input frame buffer contains the original video frame which can be used for additional processing\n * such as applying filters to it. The output frame buffer is used to receive the processed video frame\n * before sending to the encoder or renderer.\n *\n * Any exception raised (either synchronously or asynchronously) in `processFrame` will result in the frame being dropped.\n * This callback has the following signature:<br/><br/>\n * <code>processFrame(</code><br/>\n * &nbsp;&nbsp;<code>inputFrameBuffer: OffscreenCanvas | HTMLCanvasElement | HTMLVideoElement | VideoFrame,</code><br/>\n * &nbsp;&nbsp;<code>outputFrameBuffer: HTMLCanvasElement</code><br/>\n * <code>): Promise&lt;void&gt; | void;</code>\n *\n * @example\n * class GrayScaleProcessor {\n *   constructor(percentage) {\n *     this.percentage = percentage;\n *   }\n *   processFrame(inputFrameBuffer, outputFrameBuffer) {\n *     const context = outputFrameBuffer.getContext('2d');\n *     context.filter = `grayscale(${this.percentage}%)`;\n *     context.drawImage(inputFrameBuffer, 0, 0, inputFrameBuffer.width, inputFrameBuffer.height);\n *   }\n * }\n */\n\n/**\n * Possible options to provide to {@link LocalVideoTrack#addProcessor} and {@link RemoteVideoTrack#addProcessor}.\n * @typedef {object} AddProcessorOptions\n * @property {string} [inputFrameBufferType=\"offscreencanvas\"] - This option allows you to specify what kind of input you want to receive in your\n * Video Processor. The default is `offscreencanvas` and will fallback to a regular `canvas` if the browser does not support it.\n * Possible values include the following.\n * <br/>\n * <br/>\n * `videoframe` - Your Video Processor will receive a [VideoFrame](https://developer.mozilla.org/en-US/docs/Web/API/VideoFrame).\n * On browsers that do not support `VideoFrame`, it will receive an [HTMLVideoElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement) instead.\n * <br/>\n * <br/>\n * `offscreencanvas` - Your Video Processor will receive an [OffscreenCanvas](https://developer.mozilla.org/en-US/docs/Web/API/OffscreenCanvas)\n * which is good for canvas-related processing that can be rendered off screen.\n * <br/>\n * <br/>\n * `canvas` - Your Video Processor will receive an [HTMLCanvasElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement).\n * This is recommended on browsers that doesn't support `OffscreenCanvas`, or if you need to render the frame on the screen.\n * <br/>\n * <br/>\n * `video` - Your Video Processor will receive an [HTMLVideoElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLVideoElement).\n * Use this option if you are processing the frame using WebGL or if you only need to [draw](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/drawImage)\n * the frame directly to your output canvas.\n * @property {string} [outputFrameBufferContextType=\"2d\"] - The SDK needs the [context type](https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext)\n * that your Video Processor uses in order to properly generate the processed track. For example, if your Video Processor uses WebGL2 (`canvas.getContext('webgl2')`),\n * you should set `outputFrameBufferContextType` to `webgl2`. If you're using Canvas 2D processing (`canvas.getContext('2d')`),\n * you should set `outputFrameBufferContextType` to `2d`. If the output frame is an [ImageBitmap](https://developer.mozilla.org/en-US/docs/Web/API/ImageBitmap),\n * you should set `outputFrameBufferContextType` to `bitmaprenderer`.\n */\n\n/**\n * The {@link VideoTrack}'s dimensions changed.\n * @param {VideoTrack} track - The {@link VideoTrack} whose dimensions changed\n * @event VideoTrack#dimensionsChanged\n */\n\n/**\n * The {@link VideoTrack} was disabled, i.e. \"paused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was disabled\n * @event VideoTrack#disabled\n */\n\n/**\n * The {@link VideoTrack} was enabled, i.e. \"unpaused\".\n * @param {VideoTrack} track - The {@link VideoTrack} that was enabled\n * @event VideoTrack#enabled\n */\n\n/**\n * The {@link VideoTrack} started. This means there is enough video data to\n * begin playback.\n * @param {VideoTrack} track - The {@link VideoTrack} that started\n * @event VideoTrack#started\n */\n\nmodule.exports = VideoTrack;\n"],"mappings":"AAAA,YAAY;;;;;;;;;;;;;;;;;;;;;;AAEZ,IAAMA,UAAU,GAAGC,OAAO,CAAC,cAAc,CAAC;AAC1C,IAAMC,kBAAkB,GAAGD,OAAO,CAAC,sBAAsB,CAAC;AAC1D,IAAME,2BAA2B,GAAGF,OAAO,CAAC,+BAA+B,CAAC;AACpE,IAAAG,YAAY,GAAKH,OAAO,CAAC,mBAAmB,CAAC,CAAAG,YAAjC;AACZ,IAAAC,kBAAkB,GAAKJ,OAAO,CAAC,sBAAsB,CAAC,CAAAI,kBAApC;AAE1B;;;;;;;;;;;;;;;;;;;;;AAqBA,IAAAC,UAAA,0BAAAC,MAAA;EAAyBC,SAAA,CAAAF,UAAA,EAAAC,MAAA;EACvB;;;;;EAKA,SAAAD,WAAYG,qBAAqB,EAAEC,OAAO;IAA1C,IAAAC,KAAA,GACEJ,MAAA,CAAAK,IAAA,OAAMH,qBAAqB,EAAEC,OAAO,CAAC;IACrCG,MAAM,CAACC,gBAAgB,CAACH,KAAI,EAAE;MAC5BI,YAAY,EAAE;QACZC,KAAK,EAAE,KAAK;QACZC,QAAQ,EAAE;OACX;MACDC,WAAW,EAAE;QACXF,KAAK,EAAE,IAAI;QACXC,QAAQ,EAAE;OACX;MACDE,YAAY,EAAE;QACZH,KAAK,EAAE,IAAI;QACXC,QAAQ,EAAE;OACX;MACDG,uBAAuB,EAAE;QACvBJ,KAAK,EAAE,IAAI;QACXC,QAAQ,EAAE;OACX;MACDI,iBAAiB,EAAE;QACjBL,KAAK,EAAE,EAAE;QACTC,QAAQ,EAAE;OACX;MACDK,YAAY,EAAE;QACZN,KAAK,EAAE,SAAAA,CAAA,GAAO,CAAC;QACfC,QAAQ,EAAE;OACX;MACDM,cAAc,EAAE;QACdP,KAAK,EAAE,IAAI;QACXC,QAAQ,EAAE;OACX;MACDO,UAAU,EAAE;QACVC,UAAU,EAAE,IAAI;QAChBT,KAAK,EAAE;UACLU,KAAK,EAAE,IAAI;UACXC,MAAM,EAAE;;OAEX;MACDC,SAAS,EAAE;QACTH,UAAU,EAAE,IAAI;QAChBT,KAAK,EAAE,IAAI;QACXC,QAAQ,EAAE;;KAEb,CAAC;IAEFN,KAAI,CAACS,uBAAuB,GAAG,KAAKV,OAAO,CAACP,2BAA2B,IAAIA,2BAA2B,EAAEQ,KAAI,CAACkB,IAAI,CAAC;IAElH,OAAOlB,KAAI;EACb;EAEA;;;EAGAL,UAAA,CAAAwB,SAAA,CAAAC,wBAAwB,GAAxB,UAAyBC,YAAoB;IAApB,IAAAA,YAAA;MAAAA,YAAA,QAAoB;IAAA;IAC3C,IAAIC,gBAAgB,GAAG,IAAI;IAC3B,IAAIC,OAAO,GAAG,EAAE;IACV,IAAAC,EAAA,GAA0B,IAAI,CAACC,gBAAgB;MAA7CC,OAAO,GAAAF,EAAA,CAAAE,OAAA;MAAEC,UAAU,GAAAH,EAAA,CAAAG,UAA0B;IAErD,IAAI,CAACD,OAAO,EAAE;MACZJ,gBAAgB,GAAG,KAAK;MACxBC,OAAO,GAAG,8BAA8B;;IAE1C,IAAII,UAAU,KAAK,OAAO,EAAE;MAC1BL,gBAAgB,GAAG,KAAK;MACxBC,OAAO,GAAG,2BAA2B;;IAEvC,IAAI,CAAC,IAAI,CAACN,SAAS,EAAE;MACnBK,gBAAgB,GAAG,KAAK;MACxBC,OAAO,GAAG,8BAA8B;;IAE1C,IAAI,CAAC,IAAI,CAACK,YAAY,CAACC,IAAI,IAAI,CAACR,YAAY,EAAE;MAC5CC,gBAAgB,GAAG,KAAK;MACxBC,OAAO,GAAG,gEAAgE;;IAG5E,IAAIA,OAAO,EAAE;MACX,IAAI,CAACL,IAAI,CAACY,KAAK,CAACP,OAAO,CAAC;;IAE1B,OAAO;MAAED,gBAAgB,EAAAA,gBAAA;MAAEC,OAAO,EAAAA;IAAA,CAAE;EACtC,CAAC;EAED;;;EAGA5B,UAAA,CAAAwB,SAAA,CAAAY,cAAc,GAAd;IAAA,IAAA/B,KAAA;IACE,IAAI,IAAI,CAACI,YAAY,EAAE;MACrB,IAAI,CAACc,IAAI,CAACY,KAAK,CAAC,6DAA6D,CAAC;MAC9E;;IAEF,IAAI,CAAC,IAAI,CAACV,wBAAwB,EAAE,CAACE,gBAAgB,EAAE;MACrD,IAAI,CAAClB,YAAY,GAAG,KAAK;MACzB,IAAI,CAACc,IAAI,CAACY,KAAK,CAAC,qDAAqD,CAAC;MACtE;;IAEF,IAAI,CAAC1B,YAAY,GAAG,IAAI;IACxB,IAAI,CAACK,uBAAuB,CAACuB,IAAI,CAAC,OAAO,CAAC;IAC1C,IAAI,CAACd,IAAI,CAACY,KAAK,CAAC,wBAAwB,CAAC;IAEjC,IAAAG,oBAAoB,GAAK,IAAI,CAACvB,iBAAiB,CAAAuB,oBAA3B;IAE5B,IAAI,CAACC,QAAQ,CAACC,IAAI,EAAE,CAACC,IAAI,CAAC;MACxB,IAAMC,OAAO,GAAG,SAAAA,CAAAC,UAAU;QACxB,IAAMC,WAAW,GAAGvC,KAAI,CAACoB,wBAAwB,EAAE;QACnD,IAAI,CAACmB,WAAW,CAACjB,gBAAgB,EAAE;UACjC,IAAIgB,UAAU,EAAE;YACdA,UAAU,CAACE,KAAK,EAAE;;UAEpBxC,KAAI,CAACI,YAAY,GAAG,KAAK;UACzBJ,KAAI,CAACW,YAAY,EAAE;UACnBX,KAAI,CAACS,uBAAuB,CAACuB,IAAI,CAAC,MAAM,EAAEO,WAAW,CAAChB,OAAO,CAAC;UAC9DvB,KAAI,CAACkB,IAAI,CAACY,KAAK,CAAC,mDAAmD,CAAC;UACpE,OAAOW,OAAO,CAACC,OAAO,EAAE;;QAEpB,IAAAlB,EAAA,GAA4BxB,KAAI,CAACyB,gBAAgB,CAACkB,WAAW,EAAE;UAA7DC,EAAA,GAAApB,EAAA,CAAAT,KAAS;UAATA,KAAK,GAAA6B,EAAA,cAAG,CAAC,GAAAA,EAAA;UAAEC,EAAA,GAAArB,EAAA,CAAAR,MAAU;UAAVA,MAAM,GAAA6B,EAAA,cAAG,CAAC,GAAAA,EAAwC;QACrE;QACA;QACA,IAAI7C,KAAI,CAACQ,YAAY,IAAIR,KAAI,CAACQ,YAAY,CAACO,KAAK,KAAKA,KAAK,EAAE;UAC1Df,KAAI,CAACQ,YAAY,CAACO,KAAK,GAAGA,KAAK;UAC/Bf,KAAI,CAACQ,YAAY,CAACQ,MAAM,GAAGA,MAAM;;QAEnC,IAAIhB,KAAI,CAACO,WAAW,EAAE;UACpB,IAAIP,KAAI,CAACO,WAAW,CAACQ,KAAK,KAAKA,KAAK,EAAE;YACpCf,KAAI,CAACO,WAAW,CAACQ,KAAK,GAAGA,KAAK;YAC9Bf,KAAI,CAACO,WAAW,CAACS,MAAM,GAAGA,MAAM;;UAElChB,KAAI,CAACO,WAAW,CAACuC,UAAU,CAAC,IAAI,CAAC,CAACC,SAAS,CACzC/C,KAAI,CAACkC,QAAQ,EACb,CAAC,EACD,CAAC,EACDnB,KAAK,EACLC,MAAM,CACP;;QAEH,IAAMgC,KAAK,GAAGV,UAAU,KACtB,CAAC,OAAO,EAAE,YAAY,CAAC,CAACW,QAAQ,CAAChB,oBAAoB,CAAC,GAClDjC,KAAI,CAACkC,QAAQ,GACblC,KAAI,CAACO,WAAW,CACrB;QACD,IAAI2C,MAAM,GAAG,IAAI;QAEjB,IAAI;UACFA,MAAM,GAAGlD,KAAI,CAACiB,SAAS,CAACkC,YAAY,CAACH,KAAK,EAAEhD,KAAI,CAACQ,YAAY,CAAC;SAC/D,CAAC,OAAO4C,EAAE,EAAE;UACXpD,KAAI,CAACkB,IAAI,CAACY,KAAK,CAAC,gDAAgD,EAAEsB,EAAE,CAAC;;QAEvE,OAAO,CAAEF,MAAM,YAAYT,OAAO,GAAIS,MAAM,GAAGT,OAAO,CAACC,OAAO,CAACQ,MAAM,CAAC,EACnEd,IAAI,CAAC;UACJ,IAAIpC,KAAI,CAACQ,YAAY,EAAE;YACrB,IAAI,OAAOR,KAAI,CAACqD,cAAc,CAACC,YAAY,KAAK,UAAU,EAAE;cAC1DtD,KAAI,CAACqD,cAAc,CAACC,YAAY,EAAE;;YAEpCtD,KAAI,CAACS,uBAAuB,CAACuB,IAAI,CAAC,OAAO,CAAC;;QAE9C,CAAC,CAAC;MACN,CAAC;MACDhC,KAAI,CAACW,YAAY,GAAGpB,kBAAkB,CACpCS,KAAI,CAACkC,QAAQ,EACbG,OAAO,EACPJ,oBAAoB,CACrB;IACH,CAAC,CAAC,CAACsB,KAAK,CAAC,UAAAC,KAAK;MAAI,OAAAxD,KAAI,CAACkB,IAAI,CAACsC,KAAK,CAC/B,gCAAgC,EAChC;QAAEA,KAAK,EAAAA,KAAA;QAAEC,KAAK,EAAEzD;MAAI,CAAE,CACvB;IAHiB,CAGjB,CAAC;EACJ,CAAC;EAED;;;EAGAL,UAAA,CAAAwB,SAAA,CAAAuC,WAAW,GAAX;IAAA,IAAA1D,KAAA;IACEJ,MAAA,CAAAuB,SAAA,CAAMuC,WAAW,CAAAzD,IAAA,MAAE;IACnB,IAAI,IAAI,CAACiC,QAAQ,EAAE;MACjB,IAAI,CAACA,QAAQ,CAACyB,gBAAgB,GAAG;QAC/B,IAAIC,iBAAiB,CAAC5D,KAAI,EAAEA,KAAI,CAACkC,QAAQ,CAAC,EAAE;UAC1ClC,KAAI,CAACa,UAAU,CAACE,KAAK,GAAGf,KAAI,CAACkC,QAAQ,CAAC2B,UAAU;UAChD7D,KAAI,CAACa,UAAU,CAACG,MAAM,GAAGhB,KAAI,CAACkC,QAAQ,CAAC4B,WAAW;;MAEtD,CAAC;MACD,IAAI,CAAC5B,QAAQ,CAAC6B,QAAQ,GAAG;QACvB,IAAIH,iBAAiB,CAAC5D,KAAI,EAAEA,KAAI,CAACkC,QAAQ,CAAC,EAAE;UAC1ClC,KAAI,CAACa,UAAU,CAACE,KAAK,GAAGf,KAAI,CAACkC,QAAQ,CAAC2B,UAAU;UAChD7D,KAAI,CAACa,UAAU,CAACG,MAAM,GAAGhB,KAAI,CAACkC,QAAQ,CAAC4B,WAAW;UAClD,IAAI9D,KAAI,CAACgE,SAAS,EAAE;YAClBhE,KAAI,CAACkB,IAAI,CAACY,KAAK,CAAC,qBAAqB,EAAE9B,KAAI,CAACa,UAAU,CAAC;YACvDb,KAAI,CAACgC,IAAI,CAACrC,UAAU,CAACsE,kBAAkB,EAAEjE,KAAI,CAAC;;;MAGpD,CAAC;;EAEL,CAAC;EAED;;;EAGAL,UAAA,CAAAwB,SAAA,CAAA+C,iBAAiB,GAAjB;IACE,IAAMjD,SAAS,GAAG,IAAI,CAACA,SAAS;IAChC,IAAIA,SAAS,EAAE;MACb,IAAMkD,gBAAgB,GAAGjE,MAAM,CAACkE,MAAM,CAAC,EAAE,EAAE,IAAI,CAAC1D,iBAAiB,CAAC;MAClE,IAAI,CAAC2D,eAAe,CAACpD,SAAS,CAAC;MAC/B,IAAI,CAACqD,YAAY,CAACrD,SAAS,EAAEkD,gBAAgB,CAAC;;EAElD,CAAC;EAED;;;EAGAxE,UAAA,CAAAwB,SAAA,CAAAoD,MAAM,GAAN,UAAOC,OAAO;IACZ,IAAI,CAAC3D,UAAU,CAACE,KAAK,GAAGyD,OAAO,CAACX,UAAU;IAC1C,IAAI,CAAChD,UAAU,CAACG,MAAM,GAAGwD,OAAO,CAACV,WAAW;IAE5C,IAAI,CAAC5C,IAAI,CAACY,KAAK,CAAC,aAAa,EAAE,IAAI,CAACjB,UAAU,CAAC;IAC/C,IAAI,CAACmB,IAAI,CAACrC,UAAU,CAACsE,kBAAkB,EAAE,IAAI,CAAC;IAC9C,OAAOrE,MAAA,CAAAuB,SAAA,CAAMoD,MAAM,CAACtE,IAAI,CAAC,IAAI,EAAEuE,OAAO,CAAC;EACzC,CAAC;EAED;;;;;;;;;;;;;;;;;;;;;EAqBA7E,UAAA,CAAAwB,SAAA,CAAAmD,YAAY,GAAZ,UAAarD,SAAS,EAAElB,OAAO;IAA/B,IAAAC,KAAA;IACE,IAAI,CAACiB,SAAS,IAAI,OAAOA,SAAS,CAACkC,YAAY,KAAK,UAAU,EAAE;MAC9D,MAAM,IAAIsB,KAAK,CAAC,uDAAuD,CAAC;;IAE1E,IAAI,IAAI,CAACxD,SAAS,EAAE;MAClB,MAAM,IAAIwD,KAAK,CAAC,0CAA0C,CAAC;;IAE7D,IAAI,CAAC,IAAI,CAACvC,QAAQ,EAAE;MAClB,MAAM,IAAIuC,KAAK,CAAC,sCAAsC,CAAC;;IAGzD,IAAI,CAACvD,IAAI,CAACY,KAAK,CAAC,yCAAyC,EAAEb,SAAS,CAAC;IAErE,IAAI,CAAC,IAAI,CAACL,cAAc,EAAE;MACxB,IAAI,CAACA,cAAc,GAAG;QACpBZ,KAAI,CAACkB,IAAI,CAACY,KAAK,CAAC,0BAA0B,CAAC;QAC3C;QACA;QACA;QACA,IAAI9B,KAAI,CAACqD,cAAc,CAACqB,KAAK,EAAE;UAC7B1E,KAAI,CAACkB,IAAI,CAACY,KAAK,CAAC,gFAAgF,CAAC;UACjG9B,KAAI,CAACkE,iBAAiB,EAAE;;MAE5B,CAAC;MACD,IAAI,IAAI,CAACzC,gBAAgB,CAACkD,gBAAgB,EAAE;QAC1C,IAAI,CAAClD,gBAAgB,CAACkD,gBAAgB,CAAC,QAAQ,EAAE,IAAI,CAAC/D,cAAc,CAAC;OACtE,MAAM;QACL,IAAI,CAACa,gBAAgB,CAACmD,QAAQ,GAAG,IAAI,CAAChE,cAAc,CAACiE,IAAI,CAAC,IAAI,CAAC;;;IAInE,IAAI,CAACnE,iBAAiB,GAAGX,OAAO,IAAI,EAAE;IAClC,IAAAyB,EAAA,GAAyD,IAAI,CAACd,iBAAiB;MAA7EuB,oBAAoB,GAAAT,EAAA,CAAAS,oBAAA;MAAE6C,4BAA4B,GAAAtD,EAAA,CAAAsD,4BAA2B;IACnF,IAAI,OAAOC,eAAe,KAAK,WAAW,IAAI9C,oBAAoB,KAAK,iBAAiB,EAAE;MACxF,MAAM,IAAIwC,KAAK,CAAC,mDAAmD,CAAC;;IAEtE,IAAIxC,oBAAoB,IACnBA,oBAAoB,KAAK,YAAY,IACrCA,oBAAoB,KAAK,OAAO,IAChCA,oBAAoB,KAAK,QAAQ,IACjCA,oBAAoB,KAAK,iBAAiB,EAAE;MAC/C,MAAM,IAAIwC,KAAK,CAAC,qCAAmCxC,oBAAsB,CAAC;;IAE5E,IAAI,CAACA,oBAAoB,EAAE;MACzBA,oBAAoB,GAAG,OAAO8C,eAAe,KAAK,WAAW,GAAG,QAAQ,GAAG,iBAAiB;;IAGxF,IAAAnC,EAAA,GAA4D,IAAI,CAACnB,gBAAgB,CAACkB,WAAW,EAAE;MAA7FE,EAAA,GAAAD,EAAA,CAAA7B,KAAS;MAATA,KAAK,GAAA8B,EAAA,cAAG,CAAC,GAAAA,EAAA;MAAEmC,EAAA,GAAApC,EAAA,CAAA5B,MAAU;MAAVA,MAAM,GAAAgE,EAAA,cAAG,CAAC,GAAAA,EAAA;MAAEC,EAAA,GAAArC,EAAA,CAAAsC,SAA8B;MAA9BA,SAAS,GAAAD,EAAA,cAAGvF,kBAAkB,GAAAuF,EAAwC;IACrG,IAAIhD,oBAAoB,KAAK,iBAAiB,EAAE;MAC9C,IAAI,CAAC1B,WAAW,GAAG,IAAIwE,eAAe,CAAChE,KAAK,EAAEC,MAAM,CAAC;;IAEvD,IAAIiB,oBAAoB,KAAK,QAAQ,EAAE;MACrC,IAAI,CAAC1B,WAAW,GAAG4E,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC;;IAErD,IAAI,IAAI,CAAC7E,WAAW,EAAE;MACpB,IAAI,CAACA,WAAW,CAACQ,KAAK,GAAGA,KAAK;MAC9B,IAAI,CAACR,WAAW,CAACS,MAAM,GAAGA,MAAM;;IAGlC,IAAI,CAACR,YAAY,GAAG2E,QAAQ,CAACC,aAAa,CAAC,QAAQ,CAAC;IACpD,IAAI,CAAC5E,YAAY,CAACO,KAAK,GAAGA,KAAK;IAC/B,IAAI,CAACP,YAAY,CAACQ,MAAM,GAAGA,MAAM;IAEjC;IACA;IACA;IACA8D,4BAA4B,GAAGA,4BAA4B,IAAI,IAAI;IAEnE,IAAMO,GAAG,GAAG,IAAI,CAAC7E,YAAY,CAACsC,UAAU,CAACgC,4BAA4B,CAAC;IACtE,IAAI,CAACO,GAAG,EAAE;MACR,MAAM,IAAIZ,KAAK,CAAC,8CAA4CK,4BAA4B,MAAG,CAAC;;IAG9F;IACA;IACA;IACA,IAAMQ,SAAS,GAAG,OAAOC,6BAA6B,KAAK,WAAW,IAAIA,6BAA6B,CAACpE,SAAS;IAC/G;IACA,OAAOoE,6BAA6B,CAACpE,SAAS,CAACmC,YAAY,KAAK,UAAU,GAAG,CAAC,GAAGkC,SAAS;IAE5F,IAAI,CAACnC,cAAc,GAAG,IAAI,CAAC7C,YAAY,CAACiF,aAAa,CAACH,SAAS,CAAC,CAACI,SAAS,EAAE,CAAC,CAAC,CAAC;IAC/E,IAAI,CAACrC,cAAc,CAAC3B,OAAO,GAAG,IAAI,CAACD,gBAAgB,CAACC,OAAO;IAC3D,IAAI,CAACT,SAAS,GAAGA,SAAS;IAE1B,IAAI,CAACR,uBAAuB,CAACuB,IAAI,CAAC,KAAK,EAAE;MACvCf,SAAS,EAAAA,SAAA;MACT0E,aAAa,EAAE3E,MAAM;MACrB4E,YAAY,EAAE7E,KAAK;MACnB8E,cAAc,EAAEX,SAAS;MACzBY,kBAAkB,EAAE,IAAI,CAACC,QAAQ,EAAE,CAAC9C,QAAQ,CAAC,kBAAkB,CAAC;MAChEhB,oBAAoB,EAAAA,oBAAA;MACpB6C,4BAA4B,EAAAA;KAC7B,CAAC;IACF,IAAI,CAACkB,+BAA+B,EAAE;IACtC,IAAI,CAACjE,cAAc,EAAE;IACrB,OAAO,IAAI;EACb,CAAC;EAED;;;;;;;;;;;;;;IAAA,CAcE;;;;;;;;;;;;;;;;;;;;;;OAAA,CAsBA;;;;;;;;;;;;;;;;;;;;;;;;;;EA0BFpC,UAAA,CAAAwB,SAAA,CAAA8E,MAAM,GAAN;IACE,IAAM/C,MAAM,GAAGtD,MAAA,CAAAuB,SAAA,CAAM8E,MAAM,CAACC,KAAK,CAAC,IAAI,EAAEC,SAAS,CAAC;IAClD,IAAI,IAAI,CAAClF,SAAS,EAAE;MAClB,IAAI,CAACc,cAAc,EAAE;;IAEvB,OAAOmB,MAAM;EACf,CAAC;EAED;;;;;;IAAA,CAME;;;;;;;;OAAA,CAQA;;;;;;;;;EASFvD,UAAA,CAAAwB,SAAA,CAAAiF,MAAM,GAAN;IACE,OAAOxG,MAAA,CAAAuB,SAAA,CAAMiF,MAAM,CAACF,KAAK,CAAC,IAAI,EAAEC,SAAS,CAAC;EAC5C,CAAC;EAED;;;;;;;;;;;;;;;;;;;;;;EAsBAxG,UAAA,CAAAwB,SAAA,CAAAkD,eAAe,GAAf,UAAgBpD,SAAS;IACvB,IAAI,CAACA,SAAS,EAAE;MACd,MAAM,IAAIwD,KAAK,CAAC,0DAA0D,CAAC;;IAE7E,IAAI,CAAC,IAAI,CAACxD,SAAS,EAAE;MACnB,MAAM,IAAIwD,KAAK,CAAC,sCAAsC,CAAC;;IAEzD,IAAIxD,SAAS,KAAK,IAAI,CAACA,SAAS,EAAE;MAChC,MAAM,IAAIwD,KAAK,CAAC,iEAAiE,CAAC;;IAGpF,IAAI,CAAChE,uBAAuB,CAACuB,IAAI,CAAC,QAAQ,CAAC;IAC3C,IAAI,CAACd,IAAI,CAACY,KAAK,CAAC,6CAA6C,EAAEb,SAAS,CAAC;IACzE,IAAI,CAACN,YAAY,EAAE;IACnB,IAAI,CAACA,YAAY,GAAG,aAAO,CAAC;IAC5B,IAAI,CAACc,gBAAgB,CAAC4E,mBAAmB,CAAC,QAAQ,EAAE,IAAI,CAACzF,cAAc,CAAC;IACxE,IAAI,CAACF,iBAAiB,GAAG,EAAE;IAC3B,IAAI,CAACE,cAAc,GAAG,IAAI;IAC1B,IAAI,CAACR,YAAY,GAAG,KAAK;IAEzB,IAAI,CAACa,SAAS,GAAG,IAAI;IACrB,IAAI,CAACoC,cAAc,GAAG,IAAI;IAC1B,IAAI,CAAC9C,WAAW,GAAG,IAAI;IACvB,IAAI,CAACC,YAAY,GAAG,IAAI;IAExB,IAAI,CAACwF,+BAA+B,EAAE;IACtC,OAAO,IAAI;EACb,CAAC;EACH,OAAArG,UAAC;AAAD,CAAC,CAvewBN,UAAU;AAyenCM,UAAU,CAACsE,kBAAkB,GAAG,mBAAmB;AAEnD,SAASL,iBAAiBA,CAACH,KAAK,EAAE6C,IAAI;EACpC,OAAO7C,KAAK,CAAC5C,UAAU,CAACE,KAAK,KAAKuF,IAAI,CAACzC,UAAU,IAC5CJ,KAAK,CAAC5C,UAAU,CAACG,MAAM,KAAKsF,IAAI,CAACxC,WAAW;AACnD;AAEA;;;;;;;;AASA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BA;;;;;AAMA;;;;;AAMA;;;;;AAMA;;;;;;AAOAyC,MAAM,CAACC,OAAO,GAAG7G,UAAU","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}